{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "#from sklearn.externals import joblib\n",
    "\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating Cariac Validation Cohort....\")\n",
    "ca_validation_df = pd.read_csv('ca_validation_group_input (IQVIA validation dataset).csv')\n",
    "ca_validation_df = ca_validation_df.set_index('patient_id')\n",
    "out_ca_validation_df = ca_validation_df['codes'].str.split(',',expand = True).stack()\n",
    "out_ca_validation_df.index = out_ca_validation_df.index.droplevel(-1)\n",
    "out_ca_validation_df = pd.DataFrame(out_ca_validation_df,columns = ['codes'])\n",
    "out_ca_validation_df = out_ca_validation_df.reset_index()\n",
    "out_ca_validation_df['type'] = 2\n",
    "mask = input(\"Mask Patient IDs Yes/No?\")\n",
    "if(mask == 1 or mask =='y' or mask =='Y' or mask =='Yes'):\n",
    "\tpat_map = out_ca_validation_df['patient_id'].drop_duplicates().reset_index(drop=True).reset_index()                                         \n",
    "\tpat_map = pat_map.rename(columns = {\"index\":\"new_pat_id\"})\n",
    "\tfinal_ca_validation_df = out_ca_validation_df.merge(pat_map,how='inner',on='patient_id')  \n",
    "\tfinal_ca_validation_df = final_ca_validation_df.drop('patient_id',axis=1)                                                                 \n",
    "\tfinal_ca_validation_df = final_ca_validation_df.rename(columns = {\"new_pat_id\":\"patient_id\"})\n",
    "\tfinal_ca_validation_df = final_ca_validation_df[['patient_id','type','codes']]\n",
    "\tfinal_ca_validation_df.to_csv('ca_validation_model_input.csv',index = False)\n",
    "else:\n",
    "\tout_ca_validation_df.to_csv('ca_validation_model_input.csv',index = False)\n",
    "print(\"Caridac Validation Input Generated Sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(path)\n",
    "input_df_path = os.getcwd().strip() + '/ca_validation_model_input.csv' #Enter the name of the validation input file\n",
    "icd_map_path = os.getcwd().strip() + '/icd_map.csv'\n",
    "ft_imp_path = os.getcwd().strip() + '/feature_importance.csv'\n",
    "model_file = joblib.load(os.getcwd().strip() + '/rf_best_excl_1_CM_3_6.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df_pre = pd.read_csv(input_df_path)\n",
    "icd_map_df = pd.read_csv(icd_map_path)\n",
    "ft_imp_df = pd.read_csv(ft_imp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_list_df = pd.DataFrame(ft_imp_df['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the name of Patient Identifier column\n",
    "ptid = 'patient_id'\n",
    "\n",
    "#Enter the name of ICD code version type column\n",
    "vers_type = 'type'\n",
    "\n",
    "#Enter the name of the ICD code column\n",
    "codes = 'codes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_df = input_df_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_count = pd.DataFrame({'diag_count' : input_df.groupby('patient_id').count().codes}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amyloidosis_flag = input_df\n",
    "amyloidosis_flag['E85_flag'] = np.where(input_df['codes']=='E85','1','0')\n",
    "amyloidosis_flag['E850_flag'] = np.where(input_df['codes']=='E850','1','0')\n",
    "amyloidosis_flag['E851_flag'] = np.where(input_df['codes']=='E851','1','0')\n",
    "amyloidosis_flag['E852_flag'] = np.where(input_df['codes']=='E852','1','0')\n",
    "amyloidosis_flag['E853_flag'] = np.where(input_df['codes']=='E853','1','0')\n",
    "amyloidosis_flag['E854_flag'] = np.where(input_df['codes']=='E854','1','0')\n",
    "amyloidosis_flag['E858_flag'] = np.where(input_df['codes']=='E858','1','0')\n",
    "amyloidosis_flag['E8581_flag'] = np.where(input_df['codes']=='E8581','1','0')\n",
    "amyloidosis_flag['E8582_flag'] = np.where(input_df['codes']=='E8582','1','0')\n",
    "amyloidosis_flag['E8589_flag'] = np.where(input_df['codes']=='E8589','1','0')\n",
    "amyloidosis_flag['E859_flag'] = np.where(input_df['codes']=='E859','1','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amy_E85 = pd.DataFrame({'max_E85_flag' : amyloidosis_flag.groupby('patient_id')['E85_flag'].max()}).reset_index()\n",
    "amy_E850 = pd.DataFrame({'max_E850_flag' : amyloidosis_flag.groupby('patient_id')['E850_flag'].max()}).reset_index()\n",
    "amy_E851 = pd.DataFrame({'max_E851_flag' : amyloidosis_flag.groupby('patient_id')['E851_flag'].max()}).reset_index()\n",
    "amy_E852 = pd.DataFrame({'max_E852_flag' : amyloidosis_flag.groupby('patient_id')['E852_flag'].max()}).reset_index()\n",
    "amy_E853 = pd.DataFrame({'max_E853_flag' : amyloidosis_flag.groupby('patient_id')['E853_flag'].max()}).reset_index()\n",
    "amy_E854 = pd.DataFrame({'max_E854_flag' : amyloidosis_flag.groupby('patient_id')['E854_flag'].max()}).reset_index()\n",
    "amy_E858 = pd.DataFrame({'max_E858_flag' : amyloidosis_flag.groupby('patient_id')['E858_flag'].max()}).reset_index()\n",
    "amy_E8581 = pd.DataFrame({'max_E8581_flag' : amyloidosis_flag.groupby('patient_id')['E8581_flag'].max()}).reset_index()\n",
    "amy_E8582 = pd.DataFrame({'max_E8582_flag' : amyloidosis_flag.groupby('patient_id')['E8582_flag'].max()}).reset_index()\n",
    "amy_E8589 = pd.DataFrame({'max_E8589_flag' : amyloidosis_flag.groupby('patient_id')['E8589_flag'].max()}).reset_index()\n",
    "amy_E859 = pd.DataFrame({'max_E859_flag' : amyloidosis_flag.groupby('patient_id')['E859_flag'].max()}).reset_index()\n",
    "# amy_E85.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input_df['patient_id'].nunique()\n",
    "\n",
    "input_df['ca_flag'] = np.where(input_df['codes']=='E8582','1',np.where(input_df['codes']=='E854','1','0'))\n",
    "ca_pt = input_df[input_df['ca_flag'] == '1']\n",
    "ca_pt_id = ca_pt['patient_id']\n",
    "input_df['hf_flag'] = np.where(input_df['codes']=='I504','1',np.where(input_df['codes']=='I508','1',np.where(input_df['codes']=='I5081','1',np.where(input_df['codes']=='I50','1',np.where(input_df['codes']=='I501','1',np.where(input_df['codes']=='I502','1',np.where(input_df['codes']=='I5020','1',np.where(input_df['codes']=='I5021','1',np.where(input_df['codes']=='I5022','1',np.where(input_df['codes']=='I5023','1',np.where(input_df['codes']=='I503','1',np.where(input_df['codes']=='I5030','1',np.where(input_df['codes']=='I5031','1',np.where(input_df['codes']=='I5032','1',np.where(input_df['codes']=='I5033','1',np.where(input_df['codes']=='I5040','1',np.where(input_df['codes']=='I5041','1',np.where(input_df['codes']=='I5042','1',np.where(input_df['codes']=='I5043','1',np.where(input_df['codes']=='I50810','1',np.where(input_df['codes']=='I50811','1',np.where(input_df['codes']=='I50812','1',np.where(input_df['codes']=='I50813','1',np.where(input_df['codes']=='I50814','1',np.where(input_df['codes']=='I5082','1',np.where(input_df['codes']=='I5083','1',np.where(input_df['codes']=='I5084','1',np.where(input_df['codes']=='I5089','1',np.where(input_df['codes']=='I509','1','0')))))))))))))))))))))))))))))\n",
    "hf_pt = input_df[input_df['hf_flag'] == '1']\n",
    "hf_pt_id = hf_pt['patient_id']\n",
    "df_cd = pd.merge(input_df,ca_pt_id, how='inner', on = 'patient_id')\n",
    "# df_cd.head(5)\n",
    "pt_hf_flag = pd.DataFrame({'max_hf_flag' : df_cd.groupby('patient_id')['hf_flag'].max()}).reset_index()\n",
    "pt_input_hf_flag = pd.DataFrame({'max_hf_flag' : input_df.groupby('patient_id')['hf_flag'].max()}).reset_index()\n",
    "pt_hf_flag_0 = pt_hf_flag[pt_hf_flag['max_hf_flag']=='0']\n",
    "total_pat = input_df['patient_id'].nunique()\n",
    "ca_pat_count = ca_pt_id.nunique()\n",
    "hf_pat_count = hf_pt_id.nunique()\n",
    "ca_without_hf = pt_hf_flag_0['patient_id'].nunique()\n",
    "ca_final_patient_df = pt_hf_flag[pt_hf_flag['max_hf_flag']!='0']\n",
    "final_patient_df = pt_input_hf_flag[pt_input_hf_flag['max_hf_flag']!='0']\n",
    "ca_final_pat_id = ca_final_patient_df['patient_id']\n",
    "final_pat_id= final_patient_df['patient_id']\n",
    "final_input_df = pd.merge(input_df,final_pat_id, how='inner', on = 'patient_id')\n",
    "\n",
    "final_input_df = final_input_df[['patient_id','codes','type']]\n",
    "\n",
    "hf_pt_count = hf_pat_count-(ca_pat_count - ca_without_hf)\n",
    "ca_pt_count = ca_pat_count - ca_without_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A total of \" + str(total_pat) + \" patients were found. Out of which we discovered \" + str(ca_pat_count - ca_without_hf)  + \" as Cardiac Amyloid patients and a total of \" + str(hf_pat_count-(ca_pat_count - ca_without_hf))  + \" Heart Failure Patients.\")\n",
    "if (ca_pat_count - ca_without_hf == 0 ):\n",
    "    print(\"Please provide sample data for a few Cardiac Amyloid patients as well as heart failure patients.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype1 = dict(codes = str, type = str)\n",
    "\n",
    "potential_target_leaks = ['cardiomyopathy_in_diseases_classified_elsewhere','other_forms_of_heart_disease']\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    def mis_val(df):\n",
    "        #print (\"Count of NA's \\n\",df.isnull().sum())\n",
    "        nans = lambda df: df[df.isnull().any(axis=1)]\n",
    "        #print (\"\\n Rows with NA's \\r\\n\", nans(df))\n",
    "        df_wo_na = df.dropna()\n",
    "        return df_wo_na\n",
    "    \n",
    "    df_cln = mis_val(df)\n",
    "    \n",
    "    def icd_fix(icd_version):\n",
    "        conditions =  (icd_version.str.contains('10'))| (icd_version == '2'),(icd_version.str.contains('9'))| (icd_version == '1')\n",
    "        choices = ['ICD10', 'ICD9']\n",
    "        icd_fix = np.select(conditions, choices, default='NA')\n",
    "        return icd_fix\n",
    "    \n",
    "    df_cln['type_fix'] = icd_fix(df_cln[vers_type])\n",
    "    \n",
    "    df_map = pd.merge(df_cln,icd_map_df,left_on=[\"type_fix\",codes],right_on=[\"type\",\"codes\"] ,how = 'left')\n",
    "    \n",
    "    df_map_cln = mis_val(df_map)\n",
    "        \n",
    "    keys = ['short_desc','major','sub_chapter']\n",
    "\n",
    "    df_feature = df_map_cln.melt(id_vars= ptid,value_vars=keys,var_name= 'source',value_name='feature') #different syntax in lower versions\n",
    "    \n",
    "    features = pd.DataFrame(df_feature['feature'].drop_duplicates())\n",
    "    \n",
    "    features['feature_cln'] = features['feature'].str.lower().str[:100].replace(to_replace=\"[^A-Za-z0-9]\", value=\"_\", regex=True)\n",
    "    \n",
    "    df_feature = df_feature.merge(features,on = 'feature',how='inner')\n",
    "    #df_feature['feature_cln'] = df_feature['feature'].str.lower().str[:100].replace(to_replace=\"[^A-Za-z0-9]\", value=\"_\", regex=True)\n",
    "    \n",
    "    df_feature = df_feature.drop(['feature'],axis=1)\n",
    "    \n",
    "    df_feature_fitler = pd.merge(ft_list_df,df_feature,left_on = 'feature',right_on= 'feature_cln',how= 'left')\n",
    "    \n",
    "    df_feature_cols = df_feature_fitler[[ptid,'feature']].copy()\n",
    "    \n",
    "    df_feature_cols['presence_flag'] = '1'\n",
    "    \n",
    "    df_ft_pivot = df_feature_cols.pivot_table(index=ptid, columns='feature', values='presence_flag', aggfunc=np.max,dropna = False,fill_value = '0')\n",
    "\n",
    "    #df_pivot_no_leaks = df_ft_pivot.drop(potential_target_leaks, axis = 1) \n",
    "    \n",
    "    return df_ft_pivot\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = preprocess(final_input_df.astype(dtype1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "target_map = {u'1': 1, u'0': 0}\n",
    "\n",
    "rf_random_predictions = model_file.predict(final_df)\n",
    "rf_random_probas = model_file.predict_proba(final_df)\n",
    "\n",
    "rf_random_predictions = pd.Series(data=rf_random_predictions, index=final_df.index, name='predicted_value')\n",
    "cols = [\n",
    "    u'probability_of_value_%s' % label\n",
    "    for (_, label) in sorted([(int(target_map[label]), label) for label in target_map])\n",
    "]\n",
    "\n",
    "rf_random_probabilities = pd.DataFrame(data=rf_random_probas, index=final_df.index, columns=cols)\n",
    "\n",
    "results_test_rf_random = pd.concat([rf_random_predictions,rf_random_probabilities],axis=1)\n",
    "\n",
    "results_test_rf_random.reset_index(level=0, inplace=True)\n",
    "#Prediction output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_pt = pd.DataFrame()\n",
    "final_input_df['cohort_flag'] = np.where(final_input_df[\"codes\"]== 'E8582' , '1',np.where(final_input_df[\"codes\"]== 'E854' , '1','0'))\n",
    "flag = final_input_df[final_input_df['cohort_flag'] == '1']\n",
    "flag_pt['patient_id'] = flag['patient_id']\n",
    "flag_pt =flag_pt.drop_duplicates()\n",
    "flag_pt['cohort_flag']  = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = pd.merge(flag_pt, results_test_rf_random, how='outer', on = 'patient_id')\n",
    "final = df_cd[['patient_id','cohort_flag','predicted_value','probability_of_value_0','probability_of_value_1']]\n",
    "\n",
    "final['cohort_f'] = np.where(final[\"cohort_flag\"]== '1', 1,0)\n",
    "final_cohort = final\n",
    "final = final.fillna(0)\n",
    "\n",
    "final = pd.merge(final, diagnosis_count, how='left', on = 'patient_id')\n",
    "\n",
    "final = pd.merge(final, amy_E85, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E850, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E851, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E852, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E853, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E854, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E858, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E8581, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E8582, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E8589, how='left', on = 'patient_id')\n",
    "final = pd.merge(final, amy_E859, how='left', on = 'patient_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = final['cohort_f']\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "preds=final['probability_of_value_1']\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "#probs = model.predict_proba(X_test)\n",
    "#preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# print ('ROC AUC'),print(roc_auc),print('')\n",
    "print ('Accuracy:'),print(metrics.accuracy_score(y_test, final['predicted_value']))\n",
    "print ('\\nF1 Score:'),print(metrics.f1_score(y_test, final['predicted_value']))\n",
    "print ('\\nRecall:'),print(metrics.recall_score(y_test, final['predicted_value']))\n",
    "print ('\\nPrecision:'),print(metrics.precision_score(y_test, final['predicted_value']))\n",
    "print ('\\nClassification report:'),print(metrics.classification_report(y_test, final['predicted_value']))\n",
    "print ('\\nConfusion matrix:'),print(metrics.confusion_matrix(y_test, final['predicted_value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, final['predicted_value'])\n",
    "f1_score = metrics.f1_score(y_test, final['predicted_value'])\n",
    "recall = metrics.recall_score(y_test, final['predicted_value'])\n",
    "precision = metrics.precision_score(y_test, final['predicted_value'])\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, final['predicted_value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = confusion_matrix[1][1]\n",
    "true_negative = confusion_matrix[0][0]\n",
    "false_positive = confusion_matrix[0][1]\n",
    "false_negative = confusion_matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame()\n",
    "matrix.loc[0,1]='Accuracy:'\n",
    "matrix.loc[0,2]= accuracy\n",
    "matrix.loc[1,1]='F1 Score:'\n",
    "matrix.loc[1,2]= f1_score\n",
    "matrix.loc[2,1]='Recall:'\n",
    "matrix.loc[2,2]= recall\n",
    "matrix.loc[3,1]='Precision:'\n",
    "matrix.loc[3,2]= precision\n",
    "matrix.loc[4,1]='ROC AUC:'\n",
    "matrix.loc[4,2]= roc_auc\n",
    "matrix.loc[5,1]= \"\"\n",
    "matrix.loc[5,2]= \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.columns=[['metric','value']]\n",
    "matrix = matrix.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_2 = pd.DataFrame()\n",
    "matrix_2.loc[0,0] = \"Confusion\"\n",
    "matrix_2.loc[0,1] = \"Matrix\"\n",
    "matrix_2.loc[0,2] = \"Predicted\"\n",
    "matrix_2.loc[0,3] = \"Predicted\"\n",
    "\n",
    "matrix_2.loc[1,2] = 1\n",
    "matrix_2.loc[1,3] = 0\n",
    "matrix_2.loc[2,0] = \"Actual\"\n",
    "matrix_2.loc[2,1] = 1\n",
    "matrix_2.loc[3,0] = \"Actual\"\n",
    "matrix_2.loc[3,1] = 0\n",
    "\n",
    "# matrix_2\n",
    "cols=[0,1,2,3]\n",
    "matrix_2 = matrix_2[cols]\n",
    "matrix_2.loc[2,2] = true_positive\n",
    "matrix_2.loc[3,3] = true_negative\n",
    "matrix_2.loc[3,2] = false_positive\n",
    "matrix_2.loc[2,3] = false_negative\n",
    "matrix_2.loc[4,0] = \"\"\n",
    "matrix_2.loc[4,1] = \"\"\n",
    "matrix_2.loc[4,2] = \"\"\n",
    "matrix_2.loc[4,3] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[0,1,2,3]\n",
    "matrix_2 = matrix_2[cols]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final['patient_id'] = final.reset_index().index\n",
    "final.shape\n",
    "\n",
    "final_df = final[['patient_id', 'cohort_flag', 'probability_of_value_1','predicted_value','diag_count','max_E85_flag','max_E850_flag','max_E851_flag','max_E852_flag','max_E853_flag','max_E854_flag','max_E858_flag','max_E8581_flag','max_E8582_flag','max_E8589_flag','max_E859_flag',]]\n",
    "final_df['type'] = np.where(final_df['cohort_flag']== '1',np.where(final_df['predicted_value']=='1',\"True Positive\",\"True Negative\"),np.where(final_df['predicted_value']=='1',\"False Positive\",\"False Negative\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.getcwd().strip()+'\\\\Validation Outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    os.chdir(output_path)\n",
    "except:\n",
    "    os.mkdir('Validation Outputs')\n",
    "    os.chdir(output_path)\n",
    "pd.DataFrame(matrix_2).to_csv('Model metrics.csv', header = False, index  = False)\n",
    "pd.DataFrame(matrix).to_csv('Model metrics.csv', mode='a', header=False, index = False)\n",
    "pd.DataFrame(final_df).to_csv('final_predictions.csv')\n",
    "# pd.DataFrame(final_merged_patient_count_list_df).to_csv('Phenotype combination comparison.csv')\n"
   ]
  }
 ],
 "metadata": {
  "creator": "velins02",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
